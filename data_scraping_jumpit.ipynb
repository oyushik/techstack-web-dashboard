{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb0178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 로깅 설정 (노트북 출력 및 콘솔에 표시됨)\n",
    "# 기존 핸들러 제거 (노트북에서 재실행 시 중복 로깅 방지)\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# 요청 헤더 (실제 브라우저처럼 보이도록 설정)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Wanted-Platform': 'web', # 필요할 수 있는 헤더\n",
    "    'Wanted-Service': 'wanted', # 필요할 수 있는 헤더\n",
    "    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7', # 언어 설정 추가\n",
    "}\n",
    "\n",
    "logging.info(\"라이브러리 임포트, 로깅 및 헤더 설정 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a74fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직종 구분 선택\n",
    "job_category = \"total\" # \"total\" # \"backend\" # \"frontend\"\n",
    "\n",
    "if job_category == \"total\":\n",
    "    job_category_url = \"?\"\n",
    "elif job_category == \"backend\":\n",
    "    job_category_url = \"?jobCategory=1&\"\n",
    "elif job_category == \"frontend\":\n",
    "    job_category_url = \"?jobCategory=2&\"\n",
    "else:\n",
    "    job_category_url = \"?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill 데이터 필터링 함수 정의\n",
    "def filter_skill_data(skill):\n",
    "    \"\"\"\n",
    "    skill 데이터에서 조건부로 특수문자를 제거하고, 단어 목록 형태로 정리합니다.\n",
    "    \"\"\"\n",
    "    if not skill:\n",
    "        return \"\"\n",
    "\n",
    "    # 0. 한글 제거\n",
    "    no_hangul = re.compile('[ㄱ-ㅣ가-힣]+')\n",
    "    filtered_skill = no_hangul.sub('', skill)\n",
    "\n",
    "    # 1. 개행 문자 제거\n",
    "    filtered_skill = filtered_skill.replace('\\n', '')\n",
    "\n",
    "    # 2. LINE SEPARATOR 제거 (U+2028)\n",
    "    filtered_skill = filtered_skill.replace('\\u2028', '')\n",
    "\n",
    "    # # 3. 특수문자 중 '#', '+'를 제외하고 제거 (온점 포함)\n",
    "    # # 제거 대상: 알파벳, 숫자, '#', '+', 공백이 아닌 모든 문자 (온점 포함)\n",
    "    # filtered_skill = re.sub(r\"[^a-zA-Z0-9#+\\s]\", \"\", filtered_skill)\n",
    "    \n",
    "\n",
    "    # 제거 대상: 알파벳, '#', '+', 공백이 아닌 모든 문자 (온점 포함)\n",
    "    filtered_skill = re.sub(r\"[^a-zA-Z#+\\s]\", \"\", filtered_skill)\n",
    "\n",
    "\n",
    "    # 4. 알파벳 오른쪽 옆에 공백 없이 붙어 있는 숫자를 제외한 모든 숫자 제거\n",
    "    def remove_standalone_numbers(text):\n",
    "        def replace(match):\n",
    "            return \"\"\n",
    "        # 숫자 앞뒤로 알파벳이 없는 경우 제거\n",
    "        return re.sub(r\"(?<![a-zA-Z])\\d+(?![a-zA-Z])\", replace, text)\n",
    "\n",
    "    filtered_skill = remove_standalone_numbers(filtered_skill)\n",
    "\n",
    "    # 5. 단어 분리, 공백 제거, 중복 제거 및 ', '로 연결\n",
    "    words = filtered_skill.split()  # 공백을 기준으로 단어 분리\n",
    "    unique_words = []\n",
    "    seen = set()\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            unique_words.append(word)\n",
    "            seen.add(word)\n",
    "\n",
    "    filtered_skill = ', '.join(unique_words)\n",
    "\n",
    "    return filtered_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764832e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_jumpit_positions():\n",
    "    \"\"\"Jumpit 채용 공고를 스크래핑하여 데이터 리스트를 반환합니다.\"\"\"\n",
    "    all_positions_data = []\n",
    "    page_no = 1\n",
    "\n",
    "    logging.info(\"Jumpit 채용 공고 스크래핑 시작\")\n",
    "\n",
    "    while True:\n",
    "        url = f\"https://jumpit-api.saramin.co.kr/api/positions{job_category_url}sort=rsp_rate&highlight=false&page={page_no}\"\n",
    "        logging.info(f\"페이지 {page_no}의 JSON 데이터 요청: {url}\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "\n",
    "            positions_list = data['result']['positions']\n",
    "\n",
    "            if not positions_list:\n",
    "                logging.info(\"더 이상 채용 공고가 없습니다. 스크래핑 종료.\")\n",
    "                break\n",
    "\n",
    "            logging.info(f\"페이지 {page_no}에서 {len(positions_list)}개의 채용 공고 발견\")\n",
    "\n",
    "            for position in positions_list:\n",
    "                company_name = position['companyName']\n",
    "                position_title = position['title']\n",
    "                tech_stacks = position['techStacks']\n",
    "                skill = ', '.join(tech_stacks) if tech_stacks else \"N/A\"\n",
    "\n",
    "                # --- 여기에 필터링 함수 적용 ---\n",
    "                filtered_skill = filter_skill_data(skill)\n",
    "                # --- 필터링 완료 ---\n",
    "\n",
    "                position_data = {\n",
    "                    'company': company_name,\n",
    "                    'position': position_title,\n",
    "                    'skill': filtered_skill,\n",
    "                }\n",
    "                all_positions_data.append(position_data)\n",
    "\n",
    "            page_no += 1\n",
    "            time.sleep(1)\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"페이지 {page_no} 요청 실패: {e}\")\n",
    "            break\n",
    "        except KeyError as e:\n",
    "            logging.error(f\"페이지 {page_no} JSON 파싱 에러 (키 에러): {e}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.error(f\"예상치 못한 에러 발생: {e}\")\n",
    "            break\n",
    "\n",
    "    return all_positions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac20aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 셀을 실행하여 스크래핑된 데이터를 가져옵니다.\n",
    "scraped_data = scrape_jumpit_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46fd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. CSV 파일 생성\n",
    "if not scraped_data:\n",
    "    logging.warning(\"수집된 데이터가 없습니다. CSV 파일을 생성하지 않습니다.\")\n",
    "else:\n",
    "    logging.info(\"수집된 데이터를 DataFrame으로 변환 중...\")\n",
    "    df = pd.DataFrame(scraped_data)\n",
    "\n",
    "    # CSV 파일을 저장할 폴더 이름\n",
    "    data_folder = 'data'\n",
    "\n",
    "    # CSV 파일 이름 설정\n",
    "    filename = f'data_jumpit_{job_category}.csv'\n",
    "\n",
    "    # 저장할 전체 경로 생성\n",
    "    filepath = os.path.join(data_folder, filename)\n",
    "\n",
    "    # 해당 폴더가 없으면 생성\n",
    "    if not os.path.exists(data_folder):\n",
    "        try:\n",
    "            os.makedirs(data_folder)\n",
    "            logging.info(f\"'{data_folder}' 폴더를 생성했습니다.\")\n",
    "        except OSError as e:\n",
    "            logging.error(f\"'{data_folder}' 폴더 생성 중 오류 발생: {e}\", exc_info=True)\n",
    "            print(f\"\\n폴더 생성 실패: {e}\")\n",
    "    else:\n",
    "        logging.info(f\"'{data_folder}' 폴더가 이미 존재합니다.\")\n",
    "\n",
    "    try:\n",
    "        # encoding='utf-8-sig' : Excel에서 한글 깨짐 방지 (BOM 포함 UTF-8)\n",
    "        df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "        logging.info(f\"DataFrame이 '{filepath}'으로 성공적으로 저장되었습니다.\")\n",
    "        print(f\"\\n파일 저장 완료: {filepath}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"DataFrame을 CSV로 저장하는 중 오류 발생: {e}\", exc_info=True)\n",
    "        print(f\"\\n파일 저장 실패: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80aa11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv(f\"data/{filename}\", encoding='utf-8-sig')\n",
    "df_read"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
