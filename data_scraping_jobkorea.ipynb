{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Xpath를 사용하여 상세 채용 공고를 감싸는 div 찾기\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# import time\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# # 설정 정보 (기존 코드와 동일)\n",
    "# stext = \"백엔드\"  # 프론트엔드 or 백엔드 or 풀스택\n",
    "# page_no = 1\n",
    "# url = f\"https://www.jobkorea.co.kr/Search/?stext={stext}&tabType=recruit&Page_No={page_no}\"\n",
    "# headers = {\n",
    "#     'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'\n",
    "# }\n",
    "\n",
    "# job_postings_data = []\n",
    "\n",
    "# try:\n",
    "#     # 웹사이트 접속 및 헤더 설정 (기존 코드와 동일)\n",
    "#     response = requests.get(url, headers=headers)\n",
    "#     response.raise_for_status()\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#     # Chrome 드라이버 설정 (기존 코드와 동일)\n",
    "#     driver = webdriver.Chrome()\n",
    "    \n",
    "#     try:\n",
    "#         # 헤더 설정 (기존 코드와 동일)\n",
    "#         driver.get(url)\n",
    "#         for key, value in headers.items():\n",
    "#             driver.execute_script(f\"Object.defineProperty(navigator, '{key}', {{get: () => '{value}'}})\")\n",
    "#         driver.refresh()\n",
    "#         driver.implicitly_wait(10)\n",
    "\n",
    "#         # 공고 목록 추출 (기존 코드와 동일)\n",
    "#         job_items = soup.select(\"article.list-item\")\n",
    "#         print(f\"총 {len(job_items)}개의 공고 발견 (BeautifulSoup)\")\n",
    "\n",
    "#         for item in job_items:\n",
    "#             try:\n",
    "#                 # 회사명 및 공고 제목 추출 (기존 코드와 동일)\n",
    "#                 gainfo_str = item.get(\"data-gainfo\")\n",
    "#                 if gainfo_str:\n",
    "#                     gainfo = json.loads(gainfo_str)\n",
    "#                     company_name = gainfo.get(\"dimension48\")\n",
    "#                     job_title = gainfo.get(\"dimension45\")\n",
    "\n",
    "#                     # 상세 내용 URL 추출 (기존 코드와 동일)\n",
    "#                     detail_link_element = item.select_one(\".information-title > a[href*='/Recruit/']\")\n",
    "#                     if detail_link_element:\n",
    "#                         detail_url_relative = detail_link_element.get(\"href\")\n",
    "#                         base_url = \"https://www.jobkorea.co.kr\"\n",
    "#                         detail_url = base_url + detail_url_relative\n",
    "\n",
    "#                         # 상세 페이지 접속 (Selenium 사용)\n",
    "#                         driver.execute_script(\"window.open('');\")\n",
    "#                         driver.switch_to.window(driver.window_handles[-1])\n",
    "#                         driver.get(detail_url)\n",
    "#                         driver.implicitly_wait(5)\n",
    "\n",
    "#                         detailed_description = \"\"\n",
    "#                         try:\n",
    "#                             # XPath를 사용하여 상세 채용 공고를 감싸는 div 찾기\n",
    "#                             recruitment_items = driver.find_element(By.XPATH, '//div[@class=\"recruitment-items\"]')\n",
    "#                             # 해당 div 아래의 모든 <p> 태그 찾기\n",
    "#                             p_elements = recruitment_items.find_elements(By.XPATH, './/p')\n",
    "#                             detailed_description = \"\\n\".join([p.text for p in p_elements])\n",
    "#                         except NoSuchElementException:\n",
    "#                             print(f\"상세 내용 추출 실패 (Selenium - XPath): {detail_url}, Could not find element with XPath\")\n",
    "#                         except Exception as e:\n",
    "#                             print(f\"상세 내용 추출 실패 (Selenium - XPath - 기타 오류): {detail_url}, 오류: {e}\")\n",
    "\n",
    "#                         job_postings_data.append({\n",
    "#                             \"회사명\": company_name,\n",
    "#                             \"공고 제목\": job_title,\n",
    "#                             \"상세 내용\": detailed_description,\n",
    "#                             \"상세 내용 URL\": detail_url\n",
    "#                         })\n",
    "\n",
    "#                         driver.close()\n",
    "#                         driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "#                         print(f\"회사명: {company_name}, 공고 제목: {job_title}, 상세 내용 (일부): {detailed_description[:50]}..., URL: {detail_url}\")\n",
    "\n",
    "#                     else:\n",
    "#                         print(\"상세 URL을 찾을 수 없습니다.\")\n",
    "#                 else:\n",
    "#                     print(\"data-gainfo 속성을 찾을 수 없습니다.\")\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"데이터 추출 실패: {e}\")\n",
    "\n",
    "#         # 수집된 데이터를 DataFrame으로 변환\n",
    "#         df = pd.DataFrame(job_postings_data)\n",
    "#         print(\"\\n--- 수집된 채용 정보 ---\")\n",
    "#         print(df)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"스크래핑 중 오류 발생 (Selenium): {e}\")\n",
    "\n",
    "#     finally:\n",
    "#         driver.quit()\n",
    "\n",
    "# except requests.exceptions.RequestException as e:\n",
    "#     print(f\"HTTP 요청 오류: {e}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"스크래핑 중 오류 발생 (BeautifulSoup 초기 로딩): {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
